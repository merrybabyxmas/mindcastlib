# preprocess_seei_single.py
import os, json, math
import pandas as pd
from datetime import datetime, timedelta

# ======================================================
# ğŸ”§ ê³ ì • ê²½ë¡œ ì„¤ì • (ì—¬ê¸°ë§Œ ìˆ˜ì •í•˜ë©´ ë¨)
# ======================================================


CONFIG = "/home/mindcastlib/mindcastlib/configs/suicide/suicide_keyword_ver2.json"

# ======================================================
# Load Config
# ======================================================
with open(CONFIG, "r") as f:
    CFG = json.load(f)

MAIN_TO_SUB = CFG["keywords"]
NEG_EMO = {"ë¶„ë…¸", "ë¶ˆì•ˆ", "ìŠ¬í””", "ìƒì²˜"}


def parse_dt(s):
    return datetime.strptime(s, "%Y-%m-%d")


# ======================================================
# Core SEEI ê³„ì‚° í•¨ìˆ˜
# ======================================================
def compute_SEEI_from_file(path):
    with open(path, "r") as f:
        data = json.load(f)["data"]

    # ğŸ”¥ news_date ê¸°ì¤€ ìë™ window ì„¤ì •
    all_dates = []
    for block in data:
        for post in block["posts"]:
            all_dates.append(parse_dt(post["news_date"]))

    if len(all_dates) == 0:
        raise ValueError("news_date ì—†ìŒ")

    base_date = min(all_dates)
    win_low = base_date - timedelta(days=3)
    win_high = base_date + timedelta(days=3)

    main_score = {k: 0 for k in MAIN_TO_SUB}
    sub_map = {k: {} for k in MAIN_TO_SUB}

    for block in data:
        for post in block["posts"]:

            t_date = parse_dt(post["news_date"])
            if not (win_low <= t_date <= win_high):
                continue

            analyses = post["analyses"]
            kw_mask = analyses["SuicideDetectionPipeLine_title"][0]["suicide_keyword_mask"]
            sub_mask = analyses["SuicideDetectionPipeLine_title"][0]["suicide_subtag_mask"]

            comments = analyses["SentimentClassificationPipeLine_comments"]
            n = len(comments)
            if n == 0:
                continue

            # ëŒ“ê¸€ ë³¼ë¥¨ score
            vol = math.log(1 + n)

            # ê°ì • ë°©í–¥ì„±
            neg = sum(1 for c in comments if c[0]["label"] in NEG_EMO)
            dr = 1 if neg / n >= 0.5 else -1

            # main + subtag
            for mk, subs in MAIN_TO_SUB.items():

                hit = kw_mask.get(mk, False) or any(sub_mask.get(s, False) for s in subs)

                if hit:
                    main_score[mk] += dr * vol

                # ëª¨ë“  subtag count ê¸°ë¡
                for s in subs:
                    if sub_mask.get(s, False):
                        sub_map[mk][s] = sub_map[mk].get(s, 0) + 1

    return main_score, sub_map


# ======================================================
# ì‹¤í–‰ í•¨ìˆ˜
# ======================================================
def run_single(input_path: str, output_path: str): # <-- ì—¬ê¸°ì— ì¸ìˆ˜ë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤
    print(f"[INFO] Loading JSON â†’ {input_path}")
    main_score, sub_map = compute_SEEI_from_file(input_path)

    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    df = pd.DataFrame([{"file": os.path.basename(input_path), **main_score}])
    df.to_csv(output_path, index=False)

    print(f"[OK] Saved â†’ {output_path}")


if __name__ == "__main__":
    import argparse
    
    # ğŸ”¥ ì»¤ë§¨ë“œ ë¼ì¸ ì¸ìˆ˜ë¥¼ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •
    parser = argparse.ArgumentParser(description="Compute SEEI score from a single analysis JSON file.")
    parser.add_argument(
        "--file", 
        type=str, 
        required=True, 
        help="Path to the input analysis JSON file (e.g., infer_*.json)"
    )
    parser.add_argument(
        "--out", 
        type=str, 
        required=True, 
        help="Path to the output CSV file (e.g., /path/to/result.csv)"
    )
    args = parser.parse_args()
    
    # ìˆ˜ì •ëœ run_single í•¨ìˆ˜ í˜¸ì¶œ
    run_single(input_path=args.file, output_path=args.out)