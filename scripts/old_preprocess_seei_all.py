import os, json, math
import pandas as pd
from datetime import datetime, timedelta
import argparse

# ======================================================
# ğŸ”§ ê³ ì • ê²½ë¡œ ì„¤ì • (CONFIGë§Œ ë‚¨ê¹€)
# ======================================================
CONFIG = "/home/mindcastlib/mindcastlib/configs/suicide/suicide_keyword_ver2.json"
# ======================================================


# ----------------------------
# Config Load
# ----------------------------
with open(CONFIG, "r") as f:
    CFG = json.load(f)

MAIN_TO_SUB = CFG["keywords"]
NEG_EMO = {"ë¶„ë…¸", "ë¶ˆì•ˆ", "ìŠ¬í””", "ìƒì²˜"}


# ----------------------------
# Utility
# ----------------------------
def parse_dt(s):
    return datetime.strptime(s, "%Y-%m-%d")


# ----------------------------
# ê°œë³„ íŒŒì¼ SEEI ê³„ì‚°
# ----------------------------
def compute_SEEI_for_file(path, start_dt):

    with open(path, "r") as f:
        data = json.load(f)["data"]

    # 3-day window
    win_low = start_dt - timedelta(days=3)
    win_high = start_dt + timedelta(days=3)

    main_score = {k: 0 for k in MAIN_TO_SUB}

    for block in data:
        for post in block["posts"]:
            t_date = parse_dt(post["news_date"])

            if not (win_low <= t_date <= win_high):
                continue

            analyses = post["analyses"]
            kw_mask = analyses["SuicideDetectionPipeLine_title"][0]["suicide_keyword_mask"]
            sub_mask = analyses["SuicideDetectionPipeLine_title"][0]["suicide_subtag_mask"]
            comments = analyses["SentimentClassificationPipeLine_comments"]

            n = len(comments)
            if n == 0:
                continue

            # ë³¼ë¥¨ ìŠ¤ì½”ì–´
            vol = math.log(1 + n)

            # ê°ì • ë°©í–¥
            neg = sum(1 for c in comments if c[0]["label"] in NEG_EMO)
            dr = 1 if neg / n >= 0.5 else -1

            # main keyword ë§¤ì¹­
            for mk, subs in MAIN_TO_SUB.items():
                hit = kw_mask.get(mk, False) or any(sub_mask.get(s, False) for s in subs)
                if hit:
                    main_score[mk] += dr * vol

    return main_score


# ----------------------------
# ì „ì²´ ì—°ë„ ì²˜ë¦¬ í•¨ìˆ˜ ìˆ˜ì •
# ----------------------------
def run_all(BASE_ROOT: str, OUTPUT_ROOT: str, YEARS: list[str]):

    os.makedirs(OUTPUT_ROOT, exist_ok=True)
    seei_range_path = f"{OUTPUT_ROOT}/SEEI_range.csv"
    seei_month_path = f"{OUTPUT_ROOT}/SEEI_raw.csv"

    rows = []

    for yy in YEARS:
        YEAR_DIR = f"{BASE_ROOT}/{yy}"
        print(f"\n[PROCESS] Year â†’ {yy}")

        if not os.path.exists(YEAR_DIR):
            print(f"[WARN] Directory not found: {YEAR_DIR}")
            continue

        for mm in sorted(os.listdir(YEAR_DIR)):
            MONTH_DIR = f"{YEAR_DIR}/{mm}"
            if not mm.isdigit() or not os.path.isdir(MONTH_DIR):
                continue

            print(f"   [Month] {yy}-{mm}")

            for rg in sorted(os.listdir(MONTH_DIR)):
                RANGE_DIR = f"{MONTH_DIR}/{rg}"
                if not os.path.isdir(RANGE_DIR):
                    continue

                json_files = [f for f in os.listdir(RANGE_DIR) if f.endswith(".json")]
                
                # íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ê±´ë„ˆëœë‹ˆë‹¤.
                if not json_files: 
                    continue 

                # range start = ex: "01-10" â†’ 01
                start_day = rg.split("-")[0]
                start_date = f"{yy}-{mm}-{start_day.zfill(2)}"

                # monthly accumulator
                acc = {mk: 0 for mk in MAIN_TO_SUB}

                for jf in json_files:
                    score = compute_SEEI_for_file(
                        f"{RANGE_DIR}/{jf}",
                        parse_dt(start_date)
                    )
                    for mk in score:
                        acc[mk] += score[mk]

                rows.append({
                    "year": int(yy),
                    "month": int(mm),
                    "range": rg,
                    **acc
                })

    # -----------------------------------------
    # Range ë‹¨ìœ„ ì €ì¥
    # -----------------------------------------
    df_range = pd.DataFrame(rows)
    df_range = df_range.sort_values(["year", "month"])
    df_range.to_csv(seei_range_path, index=False)
    print(f"\n[OK] Saved â†’ {seei_range_path}")

    # -----------------------------------------
    # Month ë‹¨ìœ„ Sum ì €ì¥
    # -----------------------------------------
    df_month = df_range.groupby(["year", "month"]).sum(numeric_only=True).reset_index()
    df_month.to_csv(seei_month_path, index=False)
    print(f"[OK] Saved â†’ {seei_month_path}")


if __name__ == "__main__":
    
    # ì»¤ë§¨ë“œ ë¼ì¸ ì¸ìˆ˜ë¥¼ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •
    parser = argparse.ArgumentParser(description="Compute SEEI score across multiple years/files.")
    parser.add_argument(
        "--root", 
        type=str, 
        required=True, 
        help="Base root directory containing year folders of analysis JSONs."
    )
    parser.add_argument(
        "--out", 
        type=str, 
        required=True, 
        help="Output directory to save the final SEEI CSV files."
    )
    parser.add_argument(
        "--years", 
        nargs='+',  # ì—¬ëŸ¬ ê°œì˜ ì¸ìˆ˜ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ìŒ
        default=["2020", "2021", "2022"], 
        help="List of years to process (e.g., 2020 2021 2022)."
    )
    args = parser.parse_args()
    
    # ìˆ˜ì •ëœ run_all í•¨ìˆ˜ í˜¸ì¶œ
    run_all(BASE_ROOT=args.root, OUTPUT_ROOT=args.out, YEARS=args.years)